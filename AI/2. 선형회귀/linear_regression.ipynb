{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # 수치 계산\n",
    "import matplotlib.pyplot as plt # 데이터 시각화\n",
    "from sklearn.linear_model import LinearRegression # 선형 회귀 모델\n",
    "from sklearn.metrics import mean_squared_error #  평균 제곱 오차 측정 함수\n",
    "from sklearn.preprocessing import PolynomialFeatures # 다항 특징 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 생성 및 시각화\n",
    "np.random.seed(195397) # 본인 학번 이용 / 난수 생성\n",
    "\n",
    "x1 = np.linspace(0,1,11)\n",
    "x2 = np.linspace(0+0.05,1+0.05,11)\n",
    "\n",
    "print(\"x1:\",x1)\n",
    "print(\"x2:\",x2)\n",
    "\n",
    "# 복잡한 관계(지수함수와 사인 함수의 결합, 임의의 노이즈 추가)\n",
    "t1 = np.sin(2*np.pi*2*x1) + np.exp(x1*1.2) + 1*np.random.rand(11)\n",
    "t2 = np.sin(2*np.pi*2*x2) + np.exp(x2*1.2) + 1*np.random.rand(11)\n",
    "\n",
    "print(\"t1:\",t1)\n",
    "print(\"t2:\",t2)\n",
    "\n",
    "plt.plot(x1,t1,'ro') #x1과 t1의 관계를 빨간색 원으로\n",
    "plt.plot(x2,t2,'bo') #x2와 t2의 관계를 파란색 원으로\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "# x1과 t1을 사용하여 선형 회귀 모델 학습, 학습 결과 평과\n",
    "# Xtrain = x1.copy() \n",
    "Xtrain = x1.reshape(-1,1).copy()\n",
    "'''\n",
    "scikit-learn은 입력데이터가 [n_samples, n_features]의 형태\n",
    "n_samples는 샘플의 수, n_features는 특성의 수\n",
    "하나의 특성만 사용하는 경우에도 이 특성을 2차원 배열의 형태로 변환해야 한다.\n",
    "reshape(-1, 1)은 데이터를 [n_samples, 1]의 형태로 만들어 줍니다.\n",
    "'''\n",
    "ytrain = t1.copy()\n",
    "# print(Xtrain)\n",
    "# print(ytrain)\n",
    "\n",
    "# fit_intercept 회귀식에 절편 포함\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "# xtrain,ytrain에 맞게 학습\n",
    "model.fit(Xtrain,ytrain)\n",
    "# 학습된 모델을 사용하여 Xtrain에 대한 예측을 수행. 결과는 ptrain에 저장.\n",
    "ptrain = model.predict(Xtrain)\n",
    "# mean_squared_error 함수를 사용하여 실제 값(ytrain)과 예측 값(ptrain) 사이의 평균 제곱 오차(MSE)를 계산. \n",
    "# MSE는 모델의 예측 성능을 평가하는 지표 중 하나.\n",
    "# msetrain = np.mean(np.power(ptrain-ytrain,2))\n",
    "msetrain = mean_squared_error(ytrain, ptrain)\n",
    "\n",
    "plt.plot(x1,ptrain,'mo-') # 모델의 예측 결과 자주색\n",
    "plt.plot(x1,t1,'ro') #학습 데이터 빨간색 원\n",
    "plt.title(\"train result\")\n",
    "plt.show()\n",
    "\n",
    "# 학습된 선형 회귀 모델\n",
    "print('coef:', model.coef_) #계수_회귀선의 기울기\n",
    "print('intercept:', model.intercept_) # 절편 y축과 만나는 지점\n",
    "\n",
    "print('y train:', ytrain) # 실제 값\n",
    "print('pred train:',ptrain) # 예측 값\n",
    "print(\"train mse:\", msetrain) # mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "Xtest = x2.reshape(-1,1).copy() # 독립변수, 2차원 배열로 변경\n",
    "ytest = t2.copy() # 종속변수\n",
    "# xtest에 대한 예측 수행\n",
    "ptest = model.predict(Xtest)\n",
    "\n",
    "plt.plot(x2,ptest,'co-') # 예측 값_청록색\n",
    "plt.plot(x2,t2,'bo') # 실제 타겟 값_파란색\n",
    "plt.title(\"test result\")\n",
    "plt.show()\n",
    "# mse\n",
    "msetest = mean_squared_error(ytest, ptest)\n",
    "print(\"test mse:\", msetest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경사 하강법 사용하여 x1, t1, 기반으로 모델 학습\n",
    "# 테스트 셋 x2, t2에서 예측 성능 평가\n",
    "from sklearn.linear_model import SGDRegressor\n",
    " \n",
    "Xtrain = x1.reshape(-1,1).copy()\n",
    "ytrain = t1.copy()\n",
    "\n",
    "model = SGDRegressor(loss=\"squared_error\", # 손실함수_제곱 오차\n",
    "                     penalty=None, # 규제 적용X\n",
    "                     fit_intercept=True, # 절편 학습\n",
    "                     max_iter=50, # 최대 반복 횟수\n",
    "                     tol=None, # 반복을 중단할 허용 오차 기준 비활성화\n",
    "                     learning_rate='constant', # 학습률은 상수\n",
    "                     eta0=0.0001, # 학습 률\n",
    "                     verbose=0, # epoch 출력여부_1일때 출력\n",
    "                     random_state=195397 # 본인학번으로 변경\n",
    ")\n",
    "# 모델 학습\n",
    "model.fit(Xtrain,ytrain)\n",
    "\n",
    "ptrain = model.predict(Xtrain)\n",
    "\n",
    "msetrain = mean_squared_error(ytrain, ptrain)\n",
    "# 학습 데이터 셋 실제값(t1)과 예측 값(ptrain)비교\n",
    "plt.plot(x1,ptrain,'mo-') # 자주색 원\n",
    "plt.plot(x1,t1,'ro') # 빨간색 원\n",
    "plt.title(\"train result\")\n",
    "plt.show()\n",
    "# 모델의 계수와 절편 출력\n",
    "print('coef:', model.coef_)\n",
    "print('intercept:', model.intercept_)\n",
    "\n",
    "print('y train:', ytrain) # 실제 값\n",
    "print('pred train:',ptrain) # 예측 값\n",
    "print(\"train mse:\", msetrain) # mse\n",
    "\n",
    "## test\n",
    "Xtest = x2.reshape(-1,1).copy()\n",
    "ytest = t2.copy()\n",
    "\n",
    "ptest = model.predict(Xtest)\n",
    "\n",
    "plt.plot(x2,ptest,'co-') # 예측 값_청록색\n",
    "plt.plot(x2,t2,'bo') # 실제 타겟 값_파란색\n",
    "plt.title(\"test result\")\n",
    "plt.show()\n",
    "\n",
    "msetest = mean_squared_error(ytest, ptest)\n",
    "print(\"test mse:\", msetest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x를 polynomial하게 변경하는 방법(degree_차수, interaction_변수 간 상호작용 특성, bias_절편 특성 포함 여부)\n",
    "# 선형회귀 -> 다항회귀\n",
    "# xtrain 데이터셋\n",
    "Xtrain = PolynomialFeatures(1,interaction_only=False, include_bias=False).fit_transform( x1.reshape(-1,1) )\n",
    "ytrain = t1.copy()\n",
    "print(Xtrain)\n",
    "print(ytrain)\n",
    "\n",
    "# xtest 데이터셋\n",
    "Xtest = PolynomialFeatures(1,interaction_only=False, include_bias=False).fit_transform( x2.reshape(-1,1) )\n",
    "ytest = t2.copy()\n",
    "print(Xtest)\n",
    "print(ytest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "# x1과 t1을 사용하여 선형 회귀 모델 학습, 학습 결과 평과\n",
    "# Xtrain = x1.copy() \n",
    "# Xtrain = x1.reshape(-1,1).copy()\n",
    "'''\n",
    "scikit-learn은 입력데이터가 [n_samples, n_features]의 형태\n",
    "n_samples는 샘플의 수, n_features는 특성의 수\n",
    "하나의 특성만 사용하는 경우에도 이 특성을 2차원 배열의 형태로 변환해야 한다.\n",
    "reshape(-1, 1)은 데이터를 [n_samples, 1]의 형태로 만들어 줍니다.\n",
    "'''\n",
    "# ytrain = t1.copy()\n",
    "# print(Xtrain)\n",
    "# print(ytrain)\n",
    "\n",
    "# fit_intercept 회귀식에 절편 포함\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "# xtrain,ytrain에 맞게 학습\n",
    "model.fit(Xtrain,ytrain)\n",
    "# 학습된 모델을 사용하여 Xtrain에 대한 예측을 수행. 결과는 ptrain에 저장.\n",
    "ptrain = model.predict(Xtrain)\n",
    "# mean_squared_error 함수를 사용하여 실제 값(ytrain)과 예측 값(ptrain) 사이의 평균 제곱 오차(MSE)를 계산. \n",
    "# MSE는 모델의 예측 성능을 평가하는 지표 중 하나.\n",
    "# msetrain = np.mean(np.power(ptrain-ytrain,2))\n",
    "msetrain = mean_squared_error(ytrain, ptrain)\n",
    "\n",
    "plt.plot(x1,ptrain,'mo-') # 모델의 예측 결과 자주색\n",
    "plt.plot(x1,t1,'ro') #학습 데이터 빨간색 원\n",
    "plt.title(\"train result\")\n",
    "plt.show()\n",
    "\n",
    "# 학습된 선형 회귀 모델\n",
    "print('coef:', model.coef_) #계수_회귀선의 기울기\n",
    "print('intercept:', model.intercept_) # 절편 y축과 만나는 지점\n",
    "\n",
    "print('y train:', ytrain) # 실제 값\n",
    "print('pred train:',ptrain) # 예측 값\n",
    "print(\"train mse:\", msetrain) # mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "# Xtest = x2.reshape(-1,1).copy() # 독립변수, 2차원 배열로 변경\n",
    "# ytest = t2.copy() # 종속변수\n",
    "# xtest에 대한 예측 수행\n",
    "ptest = model.predict(Xtest)\n",
    "\n",
    "plt.plot(x2,ptest,'co-') # 예측 값_청록색\n",
    "plt.plot(x2,t2,'bo') # 실제 타겟 값_파란색\n",
    "plt.title(\"test result\")\n",
    "plt.show()\n",
    "# mse\n",
    "msetest = mean_squared_error(ytest, ptest)\n",
    "print(\"test mse:\", msetest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lecture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
