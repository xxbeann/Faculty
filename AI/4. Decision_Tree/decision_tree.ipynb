{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html  \n",
    "https://mljar.com/blog/visualize-decision-tree/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import make_moons, make_circles\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y =  make_circles(n_samples=400,\n",
    "                     noise=0.3, #노이즈를 낮추면 좀 더 쉬운 문제\n",
    "                     factor=0.1,\n",
    "                shuffle=True, \n",
    "                random_state=195397 #본인학번이용\n",
    "                )\n",
    "\n",
    "# 데이터 나누기\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.5, \n",
    "    random_state=195397 # 본인학번으로 변경\n",
    ") \n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "# print(\"y:\", y)\n",
    "plt.scatter(X_train[:,0], X_train[:,1], c=y_train, cmap=plt.cm.brg, s=80, edgecolor='k')\n",
    "plt.scatter(X_test[:,0], X_test[:,1], c=y_test, cmap=plt.cm.brg, s=80, edgecolor='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(\n",
    "    criterion='entropy',# 불순도 측정\n",
    "    max_depth = None, # depth는 트리 깊이, 너무 깊으면 과적합 위험\n",
    "    min_samples_split=20, # 내부 노드를 분할하기 위한 최소 샘플 수\n",
    "    min_samples_leaf=1, # 리프 노드가 되기 위해 필요한 최소 샘플 수\n",
    "    max_leaf_nodes=None,\n",
    "    random_state=0 # 고정\n",
    ")\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "print('Depth :', model.get_depth() )\n",
    "print('n leaves :', model.get_n_leaves())\n",
    "\n",
    "plt.figure(figsize=(5,10))\n",
    "plot_tree(model, filled=True, node_ids=True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "pred_train = model.predict(X_train)\n",
    "\n",
    "\n",
    "DecisionBoundaryDisplay.from_estimator(\n",
    "            model, X_train, grid_resolution=100, response_method=\"predict\", cmap=plt.cm.brg, alpha=0.8, eps=0.5\n",
    ")\n",
    "plt.scatter(X_train[:,0], X_train[:,1], c=y_train, cmap=plt.cm.brg, s=80, edgecolor='k')\n",
    "plt.scatter(X_train[:,0], X_train[:,1], c=pred_train, cmap=plt.cm.brg, s=10)\n",
    "plt.show()\n",
    "\n",
    "print(\"train acc:\", np.sum(pred_train==y_train) / len(y_train) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측\n",
    "pred_test = model.predict(X_test)\n",
    "print(\"test acc:\", np.sum(pred_test==y_test) / len(y_train) )\n",
    "\n",
    "\n",
    "DecisionBoundaryDisplay.from_estimator(\n",
    "            model, X_train, grid_resolution=100, response_method=\"predict\", cmap=plt.cm.brg, alpha=0.8, eps=0.5\n",
    ")\n",
    "plt.scatter(X_test[:,0], X_test[:,1], c=y_test, cmap=plt.cm.brg, s=80, edgecolor='gray')\n",
    "plt.scatter(X_test[:,0], X_test[:,1], c=pred_test, cmap=plt.cm.brg, s=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    max_depth = None, # depth는 종료 조건X, depth는 별로 중요하지 않다.\n",
    "    min_samples_split=20, # 얼마만큼 더 쪼갤거냐가 중요한 것 같다.\n",
    "    min_samples_leaf=1,\n",
    "    max_leaf_nodes=None,\n",
    "    random_state=0 # 고정\n",
    ")\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "print('Depth :', model.get_depth() )\n",
    "print('n leaves :', model.get_n_leaves())\n",
    "\n",
    "plt.figure(figsize=(15,30))\n",
    "plot_tree(model, filled=True, node_ids=True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "pred_train = model.predict(X_train)\n",
    "\n",
    "\n",
    "DecisionBoundaryDisplay.from_estimator(\n",
    "            model, X_train, grid_resolution=100, response_method=\"predict\", cmap=plt.cm.brg, alpha=0.8, eps=0.5\n",
    ")\n",
    "plt.scatter(X_train[:,0], X_train[:,1], c=y_train, cmap=plt.cm.brg, s=80, edgecolor='k')\n",
    "plt.scatter(X_train[:,0], X_train[:,1], c=pred_train, cmap=plt.cm.brg, s=10)\n",
    "plt.show()\n",
    "\n",
    "print(\"train acc:\", np.sum(pred_train==y_train) / len(y_train) )\n",
    "\n",
    "# 예측\n",
    "pred_test = model.predict(X_test)\n",
    "print(\"test acc:\", np.sum(pred_test==y_test) / len(y_train) )\n",
    "\n",
    "\n",
    "DecisionBoundaryDisplay.from_estimator(\n",
    "            model, X_train, grid_resolution=100, response_method=\"predict\", cmap=plt.cm.brg, alpha=0.8, eps=0.5\n",
    ")\n",
    "plt.scatter(X_test[:,0], X_test[:,1], c=y_test, cmap=plt.cm.brg, s=80, edgecolor='gray')\n",
    "plt.scatter(X_test[:,0], X_test[:,1], c=pred_test, cmap=plt.cm.brg, s=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## iris data로 해보자\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.5, \n",
    "    random_state=195397 # 본인학번으로 변경\n",
    ") \n",
    "\n",
    "\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y:\", y)\n",
    "plt.scatter(X_train[:,0], X_train[:,1], c=y_train, cmap=plt.cm.brg, s=80, edgecolor='k')\n",
    "plt.scatter(X_test[:,0], X_test[:,1], c=y_test, cmap=plt.cm.brg, s=80, edgecolor='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data 통계 확인용\n",
    "from pandas.plotting import scatter_matrix\n",
    "import pandas as pd\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "scatter_matrix(pd.DataFrame(X, columns=iris['feature_names']), \n",
    "    c=y, cmap = plt.cm.brg, s=100, figsize=(10,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## iris data에 대해서 Decision Tree를 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    max_depth = None, # depth는 종료 조건X, depth는 별로 중요하지 않다.\n",
    "    min_samples_split=20, # 얼마만큼 더 쪼갤거냐가 중요한 것 같다.\n",
    "    min_samples_leaf=1,\n",
    "    max_leaf_nodes=None,\n",
    "    random_state=0 # 고정\n",
    ")\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "print('Depth :', model.get_depth() )\n",
    "print('n leaves :', model.get_n_leaves())\n",
    "\n",
    "plt.figure(figsize=(5,10))\n",
    "plot_tree(model, filled=True, node_ids=True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "pred_train = model.predict(X_train)\n",
    "\n",
    "\n",
    "# DecisionBoundaryDisplay.from_estimator(\n",
    "#             model, X_train, grid_resolution=100, response_method=\"predict\", cmap=plt.cm.brg, alpha=0.8, eps=0.5\n",
    "# )\n",
    "# plt.scatter(X_train[:,0], X_train[:,1], c=y_train, cmap=plt.cm.brg, s=80, edgecolor='k')\n",
    "# plt.scatter(X_train[:,0], X_train[:,1], c=pred_train, cmap=plt.cm.brg, s=10)\n",
    "# plt.show()\n",
    "\n",
    "print(\"train acc:\", np.sum(pred_train==y_train) / len(y_train) )\n",
    "\n",
    "# 예측\n",
    "pred_test = model.predict(X_test)\n",
    "print(\"test acc:\", np.sum(pred_test==y_test) / len(y_train) )\n",
    "\n",
    "\n",
    "# DecisionBoundaryDisplay.from_estimator(\n",
    "#             model, X_train, grid_resolution=100, response_method=\"predict\", cmap=plt.cm.brg, alpha=0.8, eps=0.5\n",
    "# )\n",
    "# plt.scatter(X_test[:,0], X_test[:,1], c=y_test, cmap=plt.cm.brg, s=80, edgecolor='gray')\n",
    "# plt.scatter(X_test[:,0], X_test[:,1], c=pred_test, cmap=plt.cm.brg, s=10)\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lecture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
